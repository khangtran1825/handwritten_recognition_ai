import cv2
import numpy as np
import onnxruntime as ort
import os
import yaml
import typing


# --- PH·∫¶N 1: C√ÅC H√ÄM PH·ª§ TR·ª¢ (ƒê√£ t√°ch t·ª´ mltu ra ƒë·ªÉ ch·∫°y ƒë·ªôc l·∫≠p) ---

def ctc_decoder(predictions, vocab):
    """Gi·∫£i m√£ k·∫øt qu·∫£ t·ª´ Model (Output Matrix -> Text)"""
    # L·∫•y index c√≥ x√°c su·∫•t cao nh·∫•t t·∫°i m·ªói b∆∞·ªõc th·ªùi gian
    pred_indices = np.argmax(predictions[0], axis=1)

    text = ""
    last_index = -1
    blank_index = len(vocab)  # K√Ω t·ª± Blank th∆∞·ªùng n·∫±m cu·ªëi c√πng

    for index in pred_indices:
        # CTC Logic: Lo·∫°i b·ªè k√Ω t·ª± tr√πng l·∫∑p li√™n ti·∫øp v√† k√Ω t·ª± Blank
        if index != last_index and index != blank_index:
            if index < len(vocab):  # ƒê·∫£m b·∫£o index h·ª£p l·ªá
                text += vocab[index]
        last_index = index

    return text


def resize_image(image, target_width, target_height):
    """Resize ·∫£nh gi·ªØ nguy√™n t·ª∑ l·ªá v√† th√™m vi·ªÅn (Padding)"""
    h, w = image.shape[:2]

    # T√≠nh t·ª∑ l·ªá scale d·ª±a tr√™n chi·ªÅu cao (ƒë·ªÉ kh·ªõp height=96)
    scale = target_height / h
    new_w = int(w * scale)

    # Resize ·∫£nh
    resized = cv2.resize(image, (new_w, target_height))

    # T·∫°o ·∫£nh n·ªÅn tr·∫Øng (ho·∫∑c ƒëen t√πy model train, th∆∞·ªùng l√† tr·∫Øng cho handwriting)
    # L∆∞u √Ω: Model mltu th∆∞·ªùng normalize v·ªÅ 0-1, padding m√†u g√¨ kh√¥ng qu√° quan tr·ªçng n·∫øu model t·ªët,
    # nh∆∞ng chu·∫©n nh·∫•t l√† padding theo gi√° tr·ªã n·ªÅn. ·ªû ƒë√¢y ta padding m√†u ƒëen (gi√° tr·ªã 0 sau khi normalize)
    # ƒë·ªÉ an to√†n nh·∫•t v·ªõi c√°c ph√©p t√≠nh ma tr·∫≠n.
    padded_image = np.ones((target_height, target_width, 3), dtype=np.uint8) * 255

    # Ch√®n ·∫£nh ƒë√£ resize v√†o
    if new_w < target_width:
        padded_image[:, :new_w, :] = resized
    else:
        padded_image = resized[:, :target_width, :]

    return padded_image


# --- PH·∫¶N 2: CLASS CH√çNH ---

class ImageToWordModel:
    def __init__(self, model_path, config_path):
        print(f"Loading model: {model_path}")

        # 1. Load Configs
        with open(config_path, "r", encoding="utf-8") as f:
            self.config = yaml.safe_load(f)

        self.vocab = self.config.get("vocab", "")
        self.height = self.config.get("height", 96)
        self.width = self.config.get("width", 1024)

        # 2. Load Model ONNX
        # N·∫øu m√°y b·∫°n c√≥ GPU th√¨ th√™m 'CUDAExecutionProvider' v√†o list providers
        self.session = ort.InferenceSession(model_path, providers=['CPUExecutionProvider'])
        self.input_name = self.session.get_inputs()[0].name

    def predict(self, image_path):
        # ƒê·ªçc ·∫£nh
        image = cv2.imread(image_path)
        if image is None:
            return "Error: Cannot read image", None

        # X·ª≠ l√Ω ·∫£nh
        processed_img = resize_image(image, self.width, self.height)

        # Chu·∫©n h√≥a (0-255 -> 0.0-1.0) v√† th√™m chi·ªÅu Batch
        img_input = processed_img.astype(np.float32) / 255.0
        img_input = np.expand_dims(img_input, axis=0)  # Shape: (1, 96, 1024, 3)

        # Ch·∫°y Model
        preds = self.session.run(None, {self.input_name: img_input})[0]

        # Gi·∫£i m√£
        text = ctc_decoder(preds, self.vocab)
        return text, image


# --- PH·∫¶N 3: CH·∫†Y TH·ª¨ ---
if __name__ == "__main__":
    # ƒê·∫∑t t√™n file c·ªßa b·∫°n ·ªü ƒë√¢y
    MODEL_FILE = "model.onnx"
    CONFIG_FILE = "configs.yaml"
    IMAGE_FILE = "test_image.jpg"  # <--- Thay t√™n ·∫£nh b·∫°n mu·ªën test v√†o ƒë√¢y

    # Ki·ªÉm tra file t·ªìn t·∫°i
    if not os.path.exists(MODEL_FILE) or not os.path.exists(CONFIG_FILE):
        print("‚ùå L·ªói: Kh√¥ng t√¨m th·∫•y file model.onnx ho·∫∑c configs.yaml trong c√πng th∆∞ m·ª•c!")
        exit()

    # Kh·ªüi t·∫°o model
    model = ImageToWordModel(MODEL_FILE, CONFIG_FILE)

    # Ch·∫°y th·ª≠
    if os.path.exists(IMAGE_FILE):
        print(f"üîç ƒêang ƒë·ªçc ·∫£nh: {IMAGE_FILE} ...")
        ket_qua, img_goc = model.predict(IMAGE_FILE)

        print("-" * 30)
        print(f"‚úÖ K·∫æT QU·∫¢: {ket_qua}")
        print("-" * 30)

        # Hi·ªÉn th·ªã ·∫£nh k√®m k·∫øt qu·∫£ tr√™n c·ª≠a s·ªï Window
        # (L∆∞u √Ω: T√™n c·ª≠a s·ªï kh√¥ng ƒë∆∞·ª£c ch·ª©a k√Ω t·ª± ti·∫øng Vi·ªát c√≥ d·∫•u n·∫øu Windows ch∆∞a c√†i font h·ªó tr·ª£)
        cv2.imshow("Ket qua: " + str(ket_qua), img_goc)

        print("üëâ B·∫•m ph√≠m b·∫•t k·ª≥ tr√™n c·ª≠a s·ªï ·∫£nh ƒë·ªÉ tho√°t...")
        cv2.waitKey(0)
        cv2.destroyAllWindows()
    else:
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file ·∫£nh: {IMAGE_FILE}")
        print("H√£y copy m·ªôt file ·∫£nh v√†o th∆∞ m·ª•c d·ª± √°n v√† ƒë·ªïi t√™n trong code.")