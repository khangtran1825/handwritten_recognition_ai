import gradio as gr
import cv2
import numpy as np
import os
from mltu.inferenceModel import OnnxInferenceModel
from mltu.utils.text_utils import ctc_decoder
from mltu.configs import BaseModelConfigs


# 1. ƒê·ªãnh nghƒ©a l·ªõp x·ª≠ l√Ω logic d·ª± ƒëo√°n ngay trong app.py
class ImageToWordModel(OnnxInferenceModel):
    def __init__(self, char_list, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.char_list = char_list

    def predict(self, image):
        # --- B∆Ø·ªöC 1: TI·ªÄN X·ª¨ L√ù (S·ª¨ D·ª§NG LOGIC T·ªêI ∆ØU NH·∫§T) ---
        img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

        # Nh·ªã ph√¢n h√≥a th√≠ch nghi ƒë·ªÉ t√°ch ch·ªØ kh·ªèi n·ªÅn b√¨a carton
        gray_blur = cv2.medianBlur(gray, 3)
        binary_inv = cv2.adaptiveThreshold(gray_blur, 255,
                                           cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                           cv2.THRESH_BINARY_INV, 11, 4)

        # Gi√£n n·ªü ƒë·ªÉ t√¨m v√πng ch·ª©a ch·ªØ
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (10, 2))
        dilated = cv2.dilate(binary_inv, kernel, iterations=1)
        contours, _ = cv2.findContours(dilated, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        # --- B∆Ø·ªöC 2: C·∫ÆT S√ÅT V√ôNG CH·ªÆ (CROP) ---
        if contours:
            main_contours = [c for c in contours if cv2.contourArea(c) > 150]
            if main_contours:
                img_h, img_w = img.shape[:2]
                valid_rects = []
                for c in main_contours:
                    x, y, w, h = cv2.boundingRect(c)
                    # L·ªçc b·ªè b√≥ng ƒë·ªï ph√≠a d∆∞·ªõi b√¨a carton (gi·ªØ l·∫°i 60% ph√≠a tr√™n)
                    if y < img_h * 0.6:
                        valid_rects.append((x, y, x + w, y + h))

                if valid_rects:
                    x_min, y_min = min([r[0] for r in valid_rects]), min([r[1] for r in valid_rects])
                    x_max, y_max = max([r[2] for r in valid_rects]), max([r[3] for r in valid_rects])
                    margin = 5
                    image_cropped = gray[max(0, y_min - margin):min(img_h, y_max + margin),
                    max(0, x_min - margin):min(img_w, x_max + margin)]
                else:
                    image_cropped = gray
            else:
                image_cropped = gray
        else:
            image_cropped = gray

        # --- B∆Ø·ªöC 3: CHU·∫®N H√ìA ƒê·∫¶U V√ÄO MODEL ---
        _, binary_final = cv2.threshold(image_cropped, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

        # Resize v√† Padding v·ªÅ chu·∫©n 1408x96
        target_h, target_w = self.input_shapes[0][1:3]
        h, w = binary_final.shape
        ratio = min(target_h / h, target_w / w)
        new_w, new_h = int(w * ratio), int(h * ratio)
        resized = cv2.resize(binary_final, (new_w, new_h))

        canvas = np.ones((target_h, target_w), dtype=np.uint8) * 255
        canvas[:new_h, :new_w] = resized

        # Model y√™u c·∫ßu 3 k√™nh m√†u ƒë·∫ßu v√†o
        final_input = cv2.cvtColor(canvas, cv2.COLOR_GRAY2BGR)

        # --- B∆Ø·ªöC 4: D·ª∞ ƒêO√ÅN ---
        image_pred = np.expand_dims(final_input, axis=0).astype(np.float32)
        preds = self.model.run(self.output_names, {self.input_names[0]: image_pred})[0]
        text = ctc_decoder(preds, self.char_list)[0]
        return text


# 2. KH·ªûI T·∫†O GIAO DI·ªÜN (GRADIO)
# Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n ƒë·∫øn file configs.yaml th·ª±c t·∫ø c·ªßa b·∫°n
configs = BaseModelConfigs.load("models/model_demo/configs.yaml")
model = ImageToWordModel(model_path=configs.model_path, char_list=configs.vocab)


def gradio_predict(img):
    if img is None: return "Vui l√≤ng cung c·∫•p ·∫£nh!"
    return model.predict(img)


with gr.Blocks(title="AI Handwriting Recognition") as demo:
    gr.Markdown("# üñãÔ∏è Nh·∫≠n Di·ªán Ch·ªØ Vi·∫øt Tay")
    with gr.Tab("T·∫£i ·∫£nh l√™n"):
        input_file = gr.Image(label="Ch·ªçn ·∫£nh t·ª´ m√°y t√≠nh", type="pil")
        output_text = gr.Textbox(label="K·∫øt qu·∫£ d·ª± ƒëo√°n")
        btn = gr.Button("D·ª± ƒëo√°n ngay", variant="primary")
        btn.click(fn=gradio_predict, inputs=input_file, outputs=output_text)

if __name__ == "__main__":
    demo.launch(inbrowser=True)